{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd3372de",
   "metadata": {},
   "source": [
    "# Making training data\n",
    "\n",
    "Here we take the various experiments that have been run and combine them into a single training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8232c2d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6f071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d78f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general libraries\n",
    "import glob\n",
    "import os\n",
    "import pathlib\n",
    "import site\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "from loguru import logger\n",
    "# data handling libraries\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "from tqdm.dask import TqdmCallback as ProgressBarDask\n",
    "from tqdm.notebook import tqdm as ProgressBar\n",
    "# plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# machine learning libraries\n",
    "import gpytorch\n",
    "from sklearn import gaussian_process as gp\n",
    "import torch\n",
    "\n",
    "import cryogrid_pytools as cg\n",
    "import pamir_mlpermafrost as pamir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d3a480",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31344a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output = pathlib.Path(\"../../pamir-CryoGrid/output/\")\n",
    "fnames = sorted(path_output.glob(\"*.zarr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cd3b7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-31 17:33:46.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m1912776063:<module>:6\u001b[0m - \u001b[1mProcessing file: ../../pamir-CryoGrid/output/cluster_config-k1500-pamir_N180-exp1.zarr\u001b[0m\n",
      "\u001b[32m2025-07-31 17:34:00.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m1912776063:<module>:6\u001b[0m - \u001b[1mProcessing file: ../../pamir-CryoGrid/output/cluster_config-k1500-pamir_N180-exp4.zarr\u001b[0m\n",
      "\u001b[32m2025-07-31 17:34:14.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m1912776063:<module>:6\u001b[0m - \u001b[1mProcessing file: ../../pamir-CryoGrid/output/cluster_config-k1500-pamir_S180-exp1.zarr\u001b[0m\n",
      "\u001b[32m2025-07-31 17:34:26.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m1912776063:<module>:6\u001b[0m - \u001b[1mProcessing file: ../../pamir-CryoGrid/output/cluster_config-k1500-pamir_S180-exp2.zarr\u001b[0m\n",
      "\u001b[32m2025-07-31 17:34:38.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m1912776063:<module>:6\u001b[0m - \u001b[1mProcessing file: ../../pamir-CryoGrid/output/cluster_config-k1500-pamir_S180-exp4.zarr\u001b[0m\n",
      "\u001b[32m2025-07-31 17:34:50.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m1912776063:<module>:6\u001b[0m - \u001b[1mProcessing file: ../../pamir-CryoGrid/output/cluster_config-k1500-pamir_S180-exp5.zarr\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# matches anything between hyphens or underscores\n",
    "pattern = re.compile(r\"[-_]?([a-zA-Z0-9]+)[_-]?\")  \n",
    "\n",
    "tables = []\n",
    "for fname in fnames:\n",
    "    logger.info(f\"Processing file: {fname}\")\n",
    "    ds = xr.open_zarr(fname, consolidated=True)\n",
    "    exp = re.findall(pattern, fname.stem)[-2]\n",
    "    df = pamir.data.process_permafrost.get_training_data_table(ds, experiment_name=exp)\n",
    "    tables.append(df)\n",
    "\n",
    "table = pd.concat(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f84d5dc",
   "metadata": {},
   "source": [
    "# Collocating variables from spatial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d163c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-30 11:23:16\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m - \u001b[33m\u001b[1mSome points in the table are not within the specified tolerance of the spatial data. Check the 'within_tolerance' column for details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fname_spatial = f'simplecache::s3://spi-pamir-cryogrid/processed-cluster_config/spatial_variables-710w365s750e400n-100m.zarr/'\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    # Open the spatial variables dataset\n",
    "    ds_spatial = xr.open_zarr(fname_spatial, storage_options=pamir.data.s3_utils.fsspec_kwargs)\n",
    "\n",
    "df_spatial = pamir.data.process_permafrost.get_collocated_spatial_data(ds_spatial, table)\n",
    "df_spatial = df_spatial.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ffa29e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "table['land_cover'] = df_spatial.land_cover\n",
    "table['temperature'] = df_spatial.temperature\n",
    "table['temperature_downscaled'] = df_spatial.temperature_downscaled\n",
    "table['precipitation'] = df_spatial.precipitation\n",
    "table['snow_melt_doy'] = df_spatial.snow_melt_doy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f6d631",
   "metadata": {},
   "source": [
    "## ERA5 summer winter temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b834663",
   "metadata": {},
   "outputs": [],
   "source": [
    "props = {\n",
    "    'consolidated': True,\n",
    "    'storage_options': {'endpoint_url': pamir.data.s3_utils.fsspec_kwargs['s3']['endpoint_url']}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72b5ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_template = \"s3://spi-pamir-c7-sdsc/era5_data/central_asia/central_asia-{year}.zarr/\"\n",
    "era5_central_asia_list = [xr.open_zarr(url_template.format(year=y), **props) for y in range(2000, 2025)]\n",
    "\n",
    "era5_central_asia = xr.concat(era5_central_asia_list, dim='time')\n",
    "\n",
    "era5_tajik = (\n",
    "    era5_central_asia[['t2m', 'tp']]\n",
    "    .sel(\n",
    "        latitude=slice(40, 36.5),\n",
    "        longitude=slice(70, 75),\n",
    "        time=slice('2000', None))\n",
    "    .rename(\n",
    "        latitude='y',\n",
    "        longitude='x',\n",
    "        tp='precip',\n",
    "        t2m='temp2m'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bccfa494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seasonal_quantiles(da, quantiles=[0.05, 0.5, 0.95], dim='time'):\n",
    "    \"\"\"\n",
    "    Calculate seasonal quantiles for a given DataArray.\n",
    "    \n",
    "    Parameters:\n",
    "        da (xr.DataArray): Input data array with a 'time' dimension.\n",
    "        quantiles (list): List of quantiles to compute.\n",
    "        dim (str): Dimension along which to compute the quantiles.\n",
    "        \n",
    "    Returns:\n",
    "        xr.DataArray: DataArray containing the computed quantiles.\n",
    "    \"\"\"\n",
    "    name = da.name\n",
    "    \n",
    "    out = (\n",
    "        da.groupby(f'{dim}.season')\n",
    "        .quantile(quantiles, dim=dim)\n",
    "        .stack(stacked=['quantile', 'season'])\n",
    "        .to_dataset(dim='stacked')\n",
    "        .drop_vars(['quantile', 'season']))\n",
    "\n",
    "    out = out.rename({\n",
    "        (q, seas): f\"{name}_{seas}_q{int(q*100):02d}\" for q, seas in out.data_vars\n",
    "    })\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c8936ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78830fd8318490a9f3895eff5e631c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating seasonal quantiles for ERA5 data:   0%|          | 0/3896 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with ProgressBarDask(desc=\"Calculating seasonal quantiles for ERA5 data\"):\n",
    "    # Calculate seasonal quantiles for temperature and precipitation\n",
    "    ds_era5_quantiles = (\n",
    "        xr.merge(\n",
    "            [get_seasonal_quantiles(era5_tajik.temp2m),\n",
    "            get_seasonal_quantiles(era5_tajik.precip)])\n",
    "        .interp_like(ds_spatial)\n",
    "        .compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02e49006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_era5_quantiles.to_zarr('../../pamir-CryoGrid/forcing/spatial_variables-710w365s750e400n-100m.zarr/', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cf99ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-30 11:23:27\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m - \u001b[33m\u001b[1mSome points in the table are not within the specified tolerance of the spatial data. Check the 'within_tolerance' column for details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "df_era5 = pamir.data.process_permafrost.get_collocated_spatial_data(\n",
    "    ds_era5_quantiles, table).filter(regex='^temp2m_|^precip_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5e6f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_era5:\n",
    "    table[key] = df_era5[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f039b5",
   "metadata": {},
   "source": [
    "# Saving table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01cab32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.dropna().to_parquet('../data/training/training_data-k1500-pamir_ns180-expX.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b26e3a",
   "metadata": {},
   "source": [
    "# Creating inference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1119bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_spatial = '../../pamir-CryoGrid/forcing/spatial_variables-710w365s750e400n-100m.zarr/'\n",
    "ds_spatial = xr.open_zarr(fname_spatial).drop_vars('spatial_ref').astype('float32').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54d1d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numcodecs.zarr3 import Blosc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79c46d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ds_spatial.data_vars:\n",
    "    ds_spatial[key].encoding = {'dtype': 'float32', 'compressors': Blosc()}\n",
    "    ds_spatial[key].attrs = {}\n",
    "\n",
    "for key in ds_spatial.coords:\n",
    "    ds_spatial[key].encoding = {}\n",
    "    ds_spatial[key].attrs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3d4dfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x165957060>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_spatial.chunk({'x': 1000, 'y': 1000}).unify_chunks().to_zarr(\n",
    "    '../data/inference/inference_variables-710w365s750e400n-100m.zarr', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f203b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inference = pamir.models.datasets.load_inference_data_from_zarr(ds_spatial.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58f2b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inference.to_parquet('../data/inference/inference_data-pamir_N180.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e70ec0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pamir-mlpermafrost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
