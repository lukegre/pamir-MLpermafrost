{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd3372de",
   "metadata": {},
   "source": [
    "# Basic exploration with simple libraries (scikit-learn)\n",
    "\n",
    "The non-production code in this notebook is used to explore the data and create a dataset for training machine learning models. It is not intended for production use.  \n",
    "As a primer, we've already decided that gaussian processes are the best choice for our problem, since we don't have enough data to train a deep learning model.\n",
    "\n",
    "Main questions: \n",
    "1) can we use the aspect-flipped data (S180) to train a model that can predict the permafrost distribution for N180 (true output)?\n",
    "   - the aspect of S180 is flipped, meaning that it is effectively predicting for a mirror image (i.e., Southern Hemisphere). This would give us a bit more data to train with. \n",
    "2) how well can out-of-the-box scikit-learn models perform on this data?\n",
    "   - extremely randomized trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8232c2d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d78f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general libraries\n",
    "import dotenv\n",
    "import fsspec\n",
    "import glob\n",
    "import os\n",
    "import pathlib\n",
    "import site\n",
    "import sys\n",
    "import warnings\n",
    "from loguru import logger\n",
    "# data handling libraries\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "# plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# machine learning libraries\n",
    "import gpytorch\n",
    "from sklearn import gaussian_process as gp\n",
    "from sklearn import model_selection \n",
    "from sklearn import ensemble \n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import pipeline\n",
    "import torch\n",
    "\n",
    "import cryogrid_pytools as cg\n",
    "import pamir_mlpermafrost as pamir\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c927f6d0",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea812ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'k1500-pamir_N180-exp1'\n",
    "\n",
    "fname_cryogrid = f'simplecache::s3://spi-pamir-cryogrid/processed-cluster_config/cluster_config-{experiment}.zarr/'\n",
    "fname_spatial = f'simplecache::s3://spi-pamir-cryogrid/processed-cluster_config/spatial_variables-710w365s750e400n-100m.zarr/'\n",
    "fname_training = f'../data/training/training_data-k1500-pamir_ns180-expX.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07601a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_name = 'ground_temp_2m'\n",
    "x_names = [\n",
    "    # 'latitude',\n",
    "    # 'longitude',\n",
    "    'altitude',\n",
    "    'slope_angle',\n",
    "    'aspect_cos',\n",
    "    'aspect_sin',\n",
    "    'albedo',\n",
    "    'emissivity',\n",
    "    'stratigraphy_index',\n",
    "    'temperature',\n",
    "    'precipitation',\n",
    "    'snow_melt_doy',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f902f1ab",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b20ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = (\n",
    "    pd.read_parquet(fname_training)\n",
    "    .pipe(pamir.data.dem_utils.calc_aspect_cos_sin)\n",
    "    [[y_name] + x_names]\n",
    "    .dropna()\n",
    "    .loc[(['S180'], slice(50001, 61501)),]\n",
    ")\n",
    "\n",
    "df_X = df_training[x_names]\n",
    "df_y = df_training[y_name] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ffbac",
   "metadata": {},
   "source": [
    "## Inference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd09df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings(category=UserWarning):\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    ds_cryogrid = xr.open_zarr(fname_cryogrid, storage_options=pamir.data.s3.fsspec_kwargs)\n",
    "    ds_spatial = xr.open_zarr(fname_spatial, storage_options=pamir.data.s3.fsspec_kwargs)\n",
    "    \n",
    "    da_cluster_labels = ds_cryogrid.cluster_labels.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b17675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    'albedo_modis': 'albedo',\n",
    "    'emissivity_aster': 'emissivity',\n",
    "    'surface_index': 'stratigraphy_index',\n",
    "}\n",
    "\n",
    "ds_inference = (\n",
    "    ds_spatial\n",
    "    .rename(rename_dict)\n",
    "    # .isel(y=slice(1000, 2500), x=slice(500, 2000))\n",
    ")\n",
    "\n",
    "df_inference = (\n",
    "    ds_inference\n",
    "    .to_dataframe()\n",
    "    .pipe(pamir.data.dem_utils.calc_aspect_cos_sin)\n",
    "    [x_names]\n",
    "    .dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4eabf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inference.to_parquet('../data/inference/inference_data-pamir_N180.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e6908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inference.shape[0] // 10_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5e6699",
   "metadata": {},
   "source": [
    "## Creating mapped target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27022c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = y_name\n",
    "da_y = cg.spatial_clusters.map_gridcells_to_clusters(\n",
    "    df_training[key].loc['S180'].loc[50000:60000].to_xarray().rename(tag='index').assign_coords(index=lambda x: x.index.astype(str).str[-4:].astype(int)),\n",
    "    ds_cryogrid.cluster_labels.compute()\n",
    ").reindex_like(ds_inference, method='nearest')\n",
    "\n",
    "mask = (ds_spatial.altitude > 3100) & (ds_spatial.surface_index > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de359bfa",
   "metadata": {},
   "source": [
    "# Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca66e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(q):\n",
    "    return pipeline.make_pipeline(\n",
    "        # preprocessing.StandardScaler(),\n",
    "        # ensemble.HistGradientBoostingRegressor(\n",
    "        #     max_iter=450,\n",
    "        #     max_depth=5,\n",
    "        #     learning_rate=0.1,\n",
    "        #     min_samples_leaf=10,\n",
    "        #     max_leaf_nodes=42,\n",
    "        #     random_state=42,\n",
    "        #     validation_fraction=0.2,\n",
    "        #     max_features=1., \n",
    "        #     categorical_features=[df_X.columns.get_loc('stratigraphy_index')],  # Use index of categorical feature\n",
    "        # )\n",
    "        ensemble.RandomForestRegressor(n_jobs=-1, n_estimators=48, min_samples_leaf=4)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbab203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    # 'q25': make_pipeline(0.25),\n",
    "    # 'q50': make_pipeline(0.5),\n",
    "    # 'q75': make_pipeline(0.75),\n",
    "    'mse': make_pipeline(0.5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64982ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for q in models:\n",
    "    model = models[q]\n",
    "\n",
    "    print(f\"Training model for quantile {q}\")\n",
    "    model.fit(df_X, df_y)\n",
    "    \n",
    "    scores[q] = model.score(df_X, df_y)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929db11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(model[0].feature_importances_, index=x_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6da7d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_to_xarray(model, df_inference):\n",
    "    yhat = model.predict(df_inference)\n",
    "\n",
    "    da_yhat = pd.Series(\n",
    "        yhat,\n",
    "        index=df_inference.index,\n",
    "        name='yhat'\n",
    "    ).to_xarray()\n",
    "\n",
    "    return da_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23c73a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_yhat = []\n",
    "for q in models:\n",
    "    print(f\"Predicting for quantile {q}\")\n",
    "    model = models[q]\n",
    "    da_yhat += predict_to_xarray(model, df_inference).rename(q),\n",
    "\n",
    "da_yhat = xr.merge(da_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7970d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iqr = da_yhat.q75 - da_yhat.q25\n",
    "# iqr.where(mask).plot.imshow(robust=True,  vmin=0, cmap='viridis', size=10, aspect=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a37bde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "water = ds_spatial.land_cover == 1\n",
    "ice = ds_spatial.land_cover == 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452907d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_yhat = da_yhat.mse.where(~water & ~ice).astype(float).plot.imshow(robust=True, cmap='Spectral_r', size=10, aspect=1.2)\n",
    "img_yhat.figure.set_dpi(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e566d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_y = da_y.where(~water & ~ice).plot.imshow(cmap='Spectral_r', size=10, aspect=1.2)\n",
    "img_y.set_clim(img_yhat.get_clim())\n",
    "img_y.figure.set_dpi(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6101079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (da_yhat.mse - da_y).astype(float)\n",
    "img = diff.where(~water & ~ice).plot.imshow(cmap='Spectral_r', size=10, aspect=1.2)\n",
    "img.figure.set_dpi(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba66fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_spatial['resid'] = da_yhat.mse - da_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245504e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ds_spatial[['altitude', 'resid', 'aspect', 'temperature']].to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ab6d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=a, x='altitude', y='resid', cmap='mako', cbar=False, bins=100, kind='hist', dropna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2cf714",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=a, x='aspect', y='resid', cmap='mako', cbar=False, bins=100, kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b0f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=a, x='temperature', y='resid', cmap='mako', cbar=False, bins=100, kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed7d46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f80ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pamir-mlpermafrost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
